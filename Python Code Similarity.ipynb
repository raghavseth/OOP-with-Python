{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b5ac6e0af22740d2cdddcf229b8e4adb",
     "grade": false,
     "grade_id": "Instructions",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Project description\n",
    "\n",
    "Goal: Create a software to compare structural similarity of two Python codes. Input file extension is ``.txt``. There are two files, ``file1.txt`` and ``file2.txt``, available here as a sample input.\n",
    "The first line of the input file is student information. The actual Python code starts at line 2. \n",
    "\n",
    "1\\. Define a function, ``get_student_info()``, that returns student's information. **(2 point)**<br>\n",
    "> Sample run:  ``get_student_info('file1.txt')``: \n",
    "\n",
    "```Python\n",
    "Out[1]: 'student 1'```\n",
    "<br>\n",
    "2\\. Define ``read_code()`` to read Python code in the file. This function returns the body of the code(without student information). **(2 point)**<br>\n",
    "> Sample run:  ``read_code('file1.txt')``:\n",
    "\n",
    "```Python\n",
    "Out[2]:\n",
    "num_sum = 0\n",
    "for x in range(10):\n",
    "   num_sum += x\n",
    "\n",
    "print(num_sum)```\n",
    "<br>\n",
    "3\\. Define a function ``python_tokenize()``, to split input codes into a list of words. Punctuations should be considered as a word in the output. This function takes text as an input, which is an output of read_code() function. **(3 point)**<br>\n",
    "> Sample run: ``python_tokenize(text1)``:\n",
    "\n",
    "```Python\n",
    "Out[3]: ['num_sum', '=', '0', 'for', 'x', 'in', 'range', '(', '10', ')', ':', 'num_sum', '+=', 'x', 'print', '(', 'num_sum', ')']```\n",
    "<br>\n",
    "4\\. Define a function ``filter_stopwords()`` to remove stop words from the tokenized list. This function takes tokenized list as an input, which is an output of python_tokenize() function. We have also provided list of stopwords to be removed. **(2 point)**<br>\n",
    "> Sample run: ``filter_stopwords(tokens)``:\n",
    "\n",
    "```Python\n",
    "Out[4]: ['num_sum', '=', '0', 'x', 'range', '(', '10', ')', ':', 'num_sum', '+=', 'x', 'print', '(', 'num_sum', ')']```\n",
    "<br>\n",
    "5\\. Define a function ``function_list()`` to return the list all the function names in the code. This function takes text as an input, which is an output of read_code() function. **(3 point)**<br>\n",
    "> Sample run: ``function_list(text1)``: \n",
    "\n",
    "```Python\n",
    "Out[5]: ['range', 'print']```\n",
    "<br>\n",
    "6\\. Define a function ``variable_list()`` to return the list of all variable names in the code. This function takes text as an input, which is an output of read_code() function. **(3 point)**<br>\n",
    "> Sample run: ``variable_list(text1)``:\n",
    "\n",
    "```Python\n",
    "Out[6]: ['num_sum']```\n",
    "<br>\n",
    "7\\. Define a function ``cosine_similarity()`` to return the cosine similarity of two codes. This function takes two tokenized lists as input, which are outputs of python_tokenize() function. **(5 point)**\n",
    "\n",
    "You need to compute **cosine similarity** of two list of tokens. Read [here] to learn about cosine similarity. \n",
    "\n",
    "As definition of cosine similarity uses norm and dot product of the vectors, you need to first define these two functions. Then you can call them while defining ``cosine_similarity()``. Here is some hint:\n",
    "    \n",
    "   ```Python\n",
    "    make a word_list vector\n",
    "    vector1 = frequenct vector of sentence 1\n",
    "    vector2 = frequency vector of sentence 2\n",
    "    cosine_similarty = dot_product(vector1. vector2)/norm(vector1).norm(vector2)\n",
    "   ```\n",
    "> Sample run: ``cosine_similarity(python_tokenize(text1), python_tokenize(text2))``:\n",
    "\n",
    "```Python\n",
    "Out[7]: 0.598764159346999```\n",
    "<br>\n",
    "8\\. Define a function ``report()``. This function accepts two text files as input arguments and creates a report file called ``similarity_report.txt``. **(5 point)**\n",
    "\n",
    "Funtion should perform following tasks in this order:\n",
    "1. Create new file called ``similarity_report.txt`` in the working directory or overwrite the file if file with same name already exists.\n",
    "2. Write report sentences to this file.Check sample file for required format of report.\n",
    "3. Close the file.\n",
    "4. This function won't return anything such as report text. It will just write report to the file.\n",
    "\n",
    "> Sample run: ``report('file1.txt', 'file2.txt')``:<br><br> No output below cell. When you call the function using this code  , ``similarity_report.txt`` file that it creates should match **EXACTLY** with ``similarity_report_sample.txt`` file given to you. Otherwise your function won't pass the test case given in the cell below.\n",
    "\n",
    "Hint - This function will use all seven funtions above.\n",
    "<br>\n",
    "<br>\n",
    "**Important notes:** \n",
    "- You can call previously defined functions while defining the current function, but you cannot define any new fuctions that are not given above.\n",
    "- Don't change function names or their parameters.\n",
    "\n",
    "[here]:https://en.wikipedia.org/wiki/Cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c80a71b5a3f667eb48c73f29cfbc77f0",
     "grade": false,
     "grade_id": "Funtion1",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_student_info(file_name):\n",
    "    # YOUR CODE HERE\n",
    "    f = open(file_name)\n",
    "    contents = f.readline()\n",
    "    f.close()\n",
    "    return contents[:-1]\n",
    "\n",
    "# get_student_info('file1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dd2a3a1aa1a327106d5ebb5f28a7a700",
     "grade": true,
     "grade_id": "Test1",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal\n",
    "result1 = 'student 1'\n",
    "assert_equal(get_student_info('file1.txt'),result1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3878dacee26b8ad60f71017b475e6b28",
     "grade": false,
     "grade_id": "Function2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def read_code(file_name):\n",
    "    # YOUR CODE HERE\n",
    "    f = open(file_name)\n",
    "    contents = f.read()\n",
    "    f.close()\n",
    "    return contents[len(get_student_info(file_name))+1:]\n",
    "\n",
    "# read_code('file1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7f4a962fae09a2e8a42f32cc3b55b6a2",
     "grade": true,
     "grade_id": "Test2",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "result2 = '''num_sum = 0\n",
    "for x in range(10):\n",
    "   num_sum += x\n",
    "\n",
    "print(num_sum)'''\n",
    "assert_equal(read_code('file1.txt'),result2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f0fd8faef0251edf6bc26dd92263c1a1",
     "grade": false,
     "grade_id": "Function3",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def python_tokenize(text):\n",
    "    # YOUR CODE HERE\n",
    "    lst1 = text.split()\n",
    "    lst2 = []\n",
    "    for i in lst1:\n",
    "        if i.find('(') != -1:\n",
    "            a = i.find('(')\n",
    "            b = i.find(')')\n",
    "            test = i[:a]+' '+i[a]+' '+i[a+1:b]+' '+i[b]+' '+i[b+1:]\n",
    "            lst2 = lst2 + test.split()\n",
    "        elif i.find('<') != -1 or i.find(':') != -1:\n",
    "            a = i.find('<')\n",
    "            b = i.find(':')\n",
    "            test = i[:a]+' '+i[a]+' '+i[a+1:b]+' '+i[b]+' '+i[b+1:]\n",
    "            lst2 = lst2 + test.split()\n",
    "        elif i.find('=1') != -1:\n",
    "            test = i.replace('=1','= 1')\n",
    "            lst2 = lst2 + test.split()\n",
    "        else:\n",
    "            lst2.append(i)\n",
    "    return lst2\n",
    "\n",
    "# text = read_code('file2.txt')\n",
    "# python_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "68757737ffb462b8a4dba7bf8a91aaab",
     "grade": true,
     "grade_id": "Test3",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "text1 = read_code('file1.txt')\n",
    "result3 = ['num_sum', '=', '0', 'for', 'x', 'in', 'range', '(', '10', ')', ':', 'num_sum', '+=', 'x', 'print', '(', 'num_sum', ')']\n",
    "assert_equal(python_tokenize(text1),result3)\n",
    "\n",
    "text2 = read_code('file2.txt')\n",
    "result3_2 = ['num', '=', '0', 'num_sum', '=', '0', 'while', 'num', '<', '10', ':', 'num_sum', '+=', 'num', 'num', '+=', '1', 'print', '(', 'num_sum', ')']\n",
    "\n",
    "assert_equal(python_tokenize(text2), result3_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7e06268f7ed60a37c1c0559471822248",
     "grade": false,
     "grade_id": "Function4",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "python_stopping_word = ['False', 'class', 'finally', 'is', 'return', 'None', 'continue', 'for', 'lambda', 'try', 'True', \n",
    "                        'def','from', 'nonlocal', 'while','and', 'del', 'global', 'not', 'with', 'as', 'elif', 'if', 'or', \n",
    "                        'yield', 'assert', 'else', 'import', 'pass', 'break', 'except', 'in', 'raise']\n",
    "def filter_stopwords(tokens):\n",
    "    # YOUR CODE HERE\n",
    "    for i in python_stopping_word:\n",
    "        if i in tokens:\n",
    "            tokens.remove(i)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6e69b5caad0731753366e90d33680a03",
     "grade": true,
     "grade_id": "Test4",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "tokens = python_tokenize(text1)\n",
    "result4 = ['num_sum', '=', '0', 'x', 'range', '(', '10', ')', ':', 'num_sum', '+=', 'x', 'print', '(', 'num_sum', ')']\n",
    "assert_equal(filter_stopwords(tokens),result4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d31aec0442a942a17742f3975be6e90d",
     "grade": false,
     "grade_id": "Function5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def function_list(text):\n",
    "    # YOUR CODE HERE\n",
    "    lst1 = text.split()\n",
    "    lst2 = []\n",
    "    for i in lst1:\n",
    "        if i.find('(') and i.find(')') != -1:\n",
    "            p1 = i.find('(')\n",
    "            p2 = i.find(')')\n",
    "            lst2.append(i[:p1])\n",
    "    return lst2\n",
    "\n",
    "# function_list(read_code('file1.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1eee6f1d890e281e768be175a0665135",
     "grade": true,
     "grade_id": "Test5",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "result5 = ['range', 'print']\n",
    "assert_equal(function_list(text1),result5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "24356b624f3efd3892a9e04dcfb3c317",
     "grade": false,
     "grade_id": "Function6",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def variable_list(text):\n",
    "    # YOUR CODE HERE\n",
    "    assignment_list = ['=', '+=', '-=', '/=', '*=']\n",
    "    j = 1\n",
    "    lst1 = text.split()\n",
    "    lst2 = []\n",
    "    for i in lst1:\n",
    "        if j == len(lst1):\n",
    "            break\n",
    "        if lst1[j] in assignment_list:\n",
    "            lst2.append(i)\n",
    "        j=j+1\n",
    "    return list(set(lst2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "82442aaf59e25fa178c41c815900efd7",
     "grade": true,
     "grade_id": "Test6",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "result6 = ['num_sum']\n",
    "assert_equal(variable_list(text1),result6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "73e347dbce755977a44c5deb7e17b491",
     "grade": false,
     "grade_id": "Function7",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def norm(vec):\n",
    "    # YOUR CODE HERE\n",
    "    import math\n",
    "    s = 0\n",
    "    for i in vec:\n",
    "        s += i**2\n",
    "    return math.sqrt(s)\n",
    "    \n",
    "def dot(vec1, vec2):\n",
    "    # YOUR CODE HERE\n",
    "    s = 0\n",
    "    for i in range(len(vec1)):\n",
    "        s += vec1[i]*vec2[i]\n",
    "    return s\n",
    "    \n",
    "def cosine_similarity(list1, list2):\n",
    "    # YOUR CODE HERE\n",
    "    vector1 = []\n",
    "    vector2 = []\n",
    "    word_list = list(set(list1+list2))\n",
    "    for i in range(len(word_list)):\n",
    "        vector1.append(list1.count(word_list[i]))\n",
    "        vector2.append(list2.count(word_list[i]))\n",
    "    cosine_similarity = dot(vector1, vector2)/(norm(vector1)*norm(vector2))\n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "aad00cfa20271a00142f0e5f29aa9e23",
     "grade": true,
     "grade_id": "Test7",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "result7 = 0.598764159346999\n",
    "sim1 = cosine_similarity(python_tokenize(text1), python_tokenize(text2))\n",
    "assert_equal(sim1, result7)\n",
    "\n",
    "result7_2 = 0.6267831705280087\n",
    "sim2 = cosine_similarity(filter_stopwords(python_tokenize(text1)), filter_stopwords(python_tokenize(text2)))\n",
    "assert_equal(sim2, result7_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "743ed465915df0147ad89fc9dfc3507e",
     "grade": false,
     "grade_id": "Function8",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def report(file1, file2):\n",
    "    # YOUR CODE HERE\n",
    "    f = open('similarity_report.txt', 'w')\n",
    "    f.write(get_student_info(file1)+'\\n')\n",
    "    f.write('variables: '+ str(variable_list(read_code(file1)))+'\\n')\n",
    "    f.write('functions: '+ str(function_list(read_code(file1)))+'\\n')\n",
    "    f.write(get_student_info(file2)+'\\n')\n",
    "    f.write('variables: '+ str(variable_list(read_code(file2)))+'\\n')\n",
    "    f.write('functions: '+ str(function_list(read_code(file2)))+'\\n')\n",
    "    f.write('Overall similarity: '+ str(cosine_similarity(python_tokenize(read_code(file1)), python_tokenize(read_code(file2))))+'\\n')\n",
    "    f.write('Similarity without stopping words: '+ str(cosine_similarity(filter_stopwords(python_tokenize(read_code(file1))), filter_stopwords(python_tokenize(read_code(file2)))))+'\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2008cff28bd42234ba042b655210cdd8",
     "grade": true,
     "grade_id": "Test8",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\"stud[84 chars]['num_sum', 'num']\\nfunctions: ['print']\\nOver[86 chars]87\\n\" != \"stud[84 chars]['num', 'num_sum']\\nfunctions: ['print']\\nOver[86 chars]87\\n\"\n  student 1\n  variables: ['num_sum']\n  functions: ['range', 'print']\n  student 2\n- variables: ['num_sum', 'num']\n?                      -------\n+ variables: ['num', 'num_sum']\n?             +++++++\n  functions: ['print']\n  Overall similarity: 0.598764159346999\n  Similarity without stopping words: 0.6267831705280087\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-ff2ca531564d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msamplereport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msamplefile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0massert_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputreport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msamplereport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python37\\lib\\unittest\\case.py\u001b[0m in \u001b[0;36massertEqual\u001b[1;34m(self, first, second, msg)\u001b[0m\n\u001b[0;32m    837\u001b[0m         \"\"\"\n\u001b[0;32m    838\u001b[0m         \u001b[0massertion_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getAssertEqualityFunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecond\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 839\u001b[1;33m         \u001b[0massertion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0massertNotEqual\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\unittest\\case.py\u001b[0m in \u001b[0;36massertMultiLineEqual\u001b[1;34m(self, first, second, msg)\u001b[0m\n\u001b[0;32m   1218\u001b[0m             \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdifflib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndiff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirstlines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecondlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m             \u001b[0mstandardMsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_truncateMessage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstandardMsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1220\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_formatMessage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstandardMsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0massertLess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python37\\lib\\unittest\\case.py\u001b[0m in \u001b[0;36mfail\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;34m\"\"\"Fail immediately, with the given message.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfailureException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0massertFalse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: \"stud[84 chars]['num_sum', 'num']\\nfunctions: ['print']\\nOver[86 chars]87\\n\" != \"stud[84 chars]['num', 'num_sum']\\nfunctions: ['print']\\nOver[86 chars]87\\n\"\n  student 1\n  variables: ['num_sum']\n  functions: ['range', 'print']\n  student 2\n- variables: ['num_sum', 'num']\n?                      -------\n+ variables: ['num', 'num_sum']\n?             +++++++\n  functions: ['print']\n  Overall similarity: 0.598764159346999\n  Similarity without stopping words: 0.6267831705280087\n"
     ]
    }
   ],
   "source": [
    "report('file1.txt', 'file2.txt')\n",
    "outputfile = open('similarity_report.txt', 'r')\n",
    "outputreport = outputfile.read()\n",
    "samplefile = open('similarity_report_sample.txt', 'r')\n",
    "samplereport = samplefile.read()\n",
    "\n",
    "assert_equal(outputreport, samplereport)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
